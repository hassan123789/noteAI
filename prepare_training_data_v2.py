"""
noteAI ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ v2.0
2026å¹´ä¸–ç•Œæœ€é«˜æ°´æº–ç‰ˆ

æ”¹å–„ç‚¹:
- Evol-Instructå½¢å¼å¯¾å¿œ
- å¤šæ¬¡å…ƒå“è³ªè©•ä¾¡
- ã‚¿ã‚¤ãƒˆãƒ«ç‰¹å¾´æŠ½å‡ºå¼·åŒ–
- é›£æ˜“åº¦ãƒ©ãƒ™ãƒ«ä»˜ã‘
"""

import json
import re
from collections import Counter
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# ============================================================
# è¨­å®š
# ============================================================

DATA_DIR = Path("data")
RAW_DATA_FILE = DATA_DIR / "raw_notes_custom.jsonl"  # åé›†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
OUTPUT_DIR = DATA_DIR / "processed"

# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
TRAINING_FILE = OUTPUT_DIR / "training_data_v2.jsonl"
EVOL_INSTRUCT_FILE = OUTPUT_DIR / "evol_instruct_data.jsonl"
QUALITY_REPORT_FILE = OUTPUT_DIR / "quality_report.json"

# å“è³ªãƒ•ã‚£ãƒ«ã‚¿è¨­å®š
QUALITY_CONFIG = {
    "min_title_length": 5,
    "max_title_length": 100,
    "min_power_score": 1.0,      # æˆåŠŸä¾‹ã®é–¾å€¤
    "min_virality_score": 50,    # ãƒã‚¤ãƒ©ãƒ«é–¾å€¤
    "exclude_patterns": [
        r"^\d+$",                 # æ•°å­—ã®ã¿
        r"^ã€.*ã€‘$",              # è¨˜å·ã®ã¿
        r"^ç¬¬\d+è©±",              # é€£è¼‰ã‚¿ã‚¤ãƒˆãƒ«
        r"^#\d+",                 # ãƒŠãƒ³ãƒãƒªãƒ³ã‚°
    ],
}

# ã‚¿ã‚¤ãƒˆãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡
TITLE_PATTERNS = {
    "question": r"[ï¼Ÿ\?]$|^ãªãœ|^ã©ã†ã—ã¦|^ã©ã†|ã¨ã¯\ï¼Ÿ",
    "number_list": r"^\d+ã¤|^\d+é¸|^\d+å€‹|TOP\d+|\d+ã¤ã®",
    "how_to": r"^ã€œã®æ–¹æ³•|ã™ã‚‹æ–¹æ³•|ã®ã‚„ã‚Šæ–¹|ã®å§‹ã‚æ–¹|ã®ã‚³ãƒ„",
    "experience": r"ã—ã¦ã¿ãŸ|ã‚„ã£ã¦ã¿ãŸ|ã‚’è©¦ã—ãŸ|ä½“é¨“è¨˜",
    "confession": r"ã—ãŸè©±|ã¨ã„ã†è©±|ã£ã¦è©±|ã®è©±$",
    "contrast": r"ã¨|vs|ã‚ˆã‚Š|ã˜ã‚ƒãªãã¦",
    "negative": r"^ã‚„ã‚ãŸ|è¾ã‚ãŸ|ã—ãªã„|æ¨ã¦ãŸ|ã‚„ã‚‰ãªã„",
    "transformation": r"ã‹ã‚‰|ã«ãªã£ãŸ|ã«å¤‰ã‚ã£ãŸ|ã§ãã‚‹ã‚ˆã†ã«",
    "emotional": r"[ï¼!]{2,}|æœ¬å½“ã«|ãƒã‚¸ã§|ã‚¬ãƒã§|ã‚ã¡ã‚ƒãã¡ã‚ƒ",
    "quotation": r"^ã€Œ|^ã€|ã€$|ã€$",
}

# ============================================================
# ã‚¿ã‚¤ãƒˆãƒ«åˆ†æ
# ============================================================

@dataclass
class TitleAnalysis:
    """ã‚¿ã‚¤ãƒˆãƒ«ã®åˆ†æçµæœ"""
    title: str
    length: int
    char_types: Dict[str, int]  # ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã€æ•°å­—ã€è¨˜å·
    patterns: List[str]         # æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³
    hooks: List[str]            # ãƒ•ãƒƒã‚¯è¦ç´ 
    difficulty: str             # easy, medium, hard
    quality_score: float        # å“è³ªã‚¹ã‚³ã‚¢ï¼ˆ0-1ï¼‰

def analyze_char_types(text: str) -> Dict[str, int]:
    """æ–‡å­—ç¨®åˆ¥ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    types = {
        "hiragana": 0,
        "katakana": 0,
        "kanji": 0,
        "number": 0,
        "symbol": 0,
        "alphabet": 0,
    }

    for char in text:
        if '\u3040' <= char <= '\u309F':
            types["hiragana"] += 1
        elif '\u30A0' <= char <= '\u30FF':
            types["katakana"] += 1
        elif '\u4E00' <= char <= '\u9FFF':
            types["kanji"] += 1
        elif char.isdigit():
            types["number"] += 1
        elif char.isalpha():
            types["alphabet"] += 1
        else:
            types["symbol"] += 1

    return types

def detect_patterns(title: str) -> List[str]:
    """ã‚¿ã‚¤ãƒˆãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º"""
    detected = []
    for pattern_name, pattern_regex in TITLE_PATTERNS.items():
        if re.search(pattern_regex, title):
            detected.append(pattern_name)
    return detected

def detect_hooks(title: str) -> List[str]:
    """ãƒ•ãƒƒã‚¯è¦ç´ ã‚’æ¤œå‡º"""
    hooks = []

    # æ•°å­—ã®ä½¿ç”¨
    if re.search(r'\d+', title):
        hooks.append("uses_numbers")

    # æ‹¬å¼§ãƒ»è¨˜å·ã®ä½¿ç”¨
    if re.search(r'ã€|ã€‘|ã€Œ|ã€|ã€|ã€', title):
        hooks.append("uses_brackets")

    # æ„Ÿæƒ…çš„ãªè¡¨ç¾
    emotional_words = ["æœ¬å½“ã«", "ãƒã‚¸ã§", "ã‚¬ãƒã§", "ã‚ã¡ã‚ƒãã¡ã‚ƒ", "è¶…", "æœ€å¼·", "ç¥"]
    for word in emotional_words:
        if word in title:
            hooks.append("emotional_language")
            break

    # ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ãƒƒã‚¯
    negative_words = ["ã‚„ã‚ãŸ", "è¾ã‚ãŸ", "ã—ãªã„", "æ¨ã¦ãŸ", "ã‚„ã‚‰ãªã„", "å¤±æ•—"]
    for word in negative_words:
        if word in title:
            hooks.append("negative_hook")
            break

    # å¤‰åŒ–ãƒ»çµæœã‚’ç¤ºå”†
    if re.search(r"ã«ãªã£ãŸ|ã§ããŸ|å¤‰ã‚ã£ãŸ|é”æˆ", title):
        hooks.append("shows_transformation")

    # é™å®šæ€§
    if re.search(r"ã ã‘|ã®ã¿|é™å®š|ç§˜å¯†", title):
        hooks.append("exclusivity")

    return list(set(hooks))

def calculate_quality_score(title: str, patterns: List[str], hooks: List[str],
                           char_types: Dict[str, int]) -> float:
    """ã‚¿ã‚¤ãƒˆãƒ«ã®å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    score = 0.5  # åŸºæº–ç‚¹

    # é•·ã•ãƒœãƒ¼ãƒŠã‚¹ï¼ˆ15-40æ–‡å­—ãŒæœ€é©ï¼‰
    length = len(title)
    if 15 <= length <= 40:
        score += 0.1
    elif length < 10 or length > 60:
        score -= 0.1

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒœãƒ¼ãƒŠã‚¹
    score += min(len(patterns) * 0.05, 0.15)

    # ãƒ•ãƒƒã‚¯ãƒœãƒ¼ãƒŠã‚¹
    score += min(len(hooks) * 0.05, 0.2)

    # æ–‡å­—ç¨®ãƒãƒ©ãƒ³ã‚¹ï¼ˆæ¼¢å­—+ã²ã‚‰ãŒãªã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
    total_chars = sum(char_types.values())
    if total_chars > 0:
        kanji_ratio = char_types["kanji"] / total_chars
        if 0.2 <= kanji_ratio <= 0.5:
            score += 0.05

    return min(max(score, 0.0), 1.0)

def determine_difficulty(title: str, patterns: List[str], power_score: float) -> str:
    """é›£æ˜“åº¦ã‚’åˆ¤å®š"""
    complexity = 0

    # ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°ã«ã‚ˆã‚‹è¤‡é›‘ã•
    complexity += len(patterns)

    # é•·ã•ã«ã‚ˆã‚‹è¤‡é›‘ã•
    if len(title) > 30:
        complexity += 1
    if len(title) > 50:
        complexity += 1

    # Power Scoreã«ã‚ˆã‚‹é›£æ˜“åº¦
    if power_score >= 3.0:
        complexity += 2  # éå¸¸ã«æˆåŠŸã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã¯å†ç¾ãŒé›£ã—ã„

    if complexity <= 2:
        return "easy"
    elif complexity <= 4:
        return "medium"
    else:
        return "hard"

def analyze_title(title: str, power_score: float = 0.0) -> TitleAnalysis:
    """ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç·åˆåˆ†æ"""
    char_types = analyze_char_types(title)
    patterns = detect_patterns(title)
    hooks = detect_hooks(title)
    quality_score = calculate_quality_score(title, patterns, hooks, char_types)
    difficulty = determine_difficulty(title, patterns, power_score)

    return TitleAnalysis(
        title=title,
        length=len(title),
        char_types=char_types,
        patterns=patterns,
        hooks=hooks,
        difficulty=difficulty,
        quality_score=quality_score,
    )

# ============================================================
# Evol-Instructå½¢å¼ç”Ÿæˆ
# ============================================================

def create_instruction_variants(title: str, analysis: TitleAnalysis,
                                category: str, power_score: float) -> List[Dict]:
    """Evol-Instructå½¢å¼ã®æŒ‡ç¤ºãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
    variants = []

    # åŸºæœ¬å½¢å¼
    base_instruction = {
        "instruction": f"ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã«é–¢ã™ã‚‹ã€èª­è€…ã‚’æƒ¹ãã¤ã‘ã‚‹noteè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚\nãƒ†ãƒ¼ãƒ: {category}",
        "input": "",
        "output": title,
        "metadata": {
            "power_score": power_score,
            "patterns": analysis.patterns,
            "hooks": analysis.hooks,
            "difficulty": analysis.difficulty,
            "quality_score": analysis.quality_score,
        }
    }
    variants.append(base_instruction)

    # ãƒ‘ã‚¿ãƒ¼ãƒ³æŒ‡å®šå½¢å¼
    if analysis.patterns:
        pattern_names = {
            "question": "ç–‘å•å½¢",
            "number_list": "æ•°å­—ãƒªã‚¹ãƒˆ",
            "how_to": "ãƒã‚¦ãƒ„ãƒ¼",
            "experience": "ä½“é¨“è«‡",
            "confession": "å‘Šç™½ç³»",
            "negative": "ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ãƒƒã‚¯",
            "transformation": "å¤‰åŒ–ãƒ»æˆé•·",
            "emotional": "æ„Ÿæƒ…çš„",
        }
        pattern_desc = "ãƒ»".join([pattern_names.get(p, p) for p in analysis.patterns[:2]])

        pattern_instruction = {
            "instruction": f"ã€Œ{pattern_desc}ã€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸã€ãƒã‚ºã‚‹noteè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
            "input": f"ã‚«ãƒ†ã‚´ãƒª: {category}",
            "output": title,
            "metadata": base_instruction["metadata"],
        }
        variants.append(pattern_instruction)

    # é›£æ˜“åº¦åˆ¥å½¢å¼ï¼ˆmediumä»¥ä¸Šã®ã¿ï¼‰
    if analysis.difficulty in ["medium", "hard"]:
        advanced_instruction = {
            "instruction": "é«˜ã„ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’ç²å¾—ã—ãŸå®Ÿç¸¾ã®ã‚ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚è€ƒã«ã€åŒæ§˜ã®åŠ¹æœãŒæœŸå¾…ã§ãã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
            "input": f"åˆ†é‡: {category}\næˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: {', '.join(analysis.patterns)}\nãƒ•ãƒƒã‚¯è¦ç´ : {', '.join(analysis.hooks)}",
            "output": title,
            "metadata": base_instruction["metadata"],
        }
        variants.append(advanced_instruction)

    return variants

# ============================================================
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†
# ============================================================

def should_include(note: Dict) -> bool:
    """è¨˜äº‹ã‚’å«ã‚ã‚‹ã¹ãã‹åˆ¤å®š"""
    title = note.get("title", "")

    # é•·ã•ãƒã‚§ãƒƒã‚¯
    if len(title) < QUALITY_CONFIG["min_title_length"]:
        return False
    if len(title) > QUALITY_CONFIG["max_title_length"]:
        return False

    # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
    for pattern in QUALITY_CONFIG["exclude_patterns"]:
        if re.match(pattern, title):
            return False

    return True

def process_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦Evol-Instructå½¢å¼ã«å¤‰æ›"""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    if not RAW_DATA_FILE.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {RAW_DATA_FILE}")
        return

    print("=" * 60)
    print("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æº–å‚™ v2.0 é–‹å§‹")
    print("=" * 60)

    # çµ±è¨ˆæƒ…å ±
    stats = {
        "total_raw": 0,
        "filtered_out": 0,
        "success_examples": 0,
        "evol_instruct_count": 0,
        "categories": Counter(),
        "patterns": Counter(),
        "difficulties": Counter(),
    }

    training_data = []
    evol_instruct_data = []

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open(RAW_DATA_FILE, "r", encoding="utf-8") as f:
        for line in f:
            try:
                note = json.loads(line)
                stats["total_raw"] += 1

                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if not should_include(note):
                    stats["filtered_out"] += 1
                    continue

                title = note["title"]
                power_score = note.get("power_score", 0)
                category = note.get("category", "unknown")

                # ã‚¿ã‚¤ãƒˆãƒ«åˆ†æ
                analysis = analyze_title(title, power_score)

                # çµ±è¨ˆæ›´æ–°
                stats["categories"][category] += 1
                for pattern in analysis.patterns:
                    stats["patterns"][pattern] += 1
                stats["difficulties"][analysis.difficulty] += 1

                # æˆåŠŸä¾‹åˆ¤å®šï¼ˆPower Score >= 1.0ï¼‰
                if power_score >= QUALITY_CONFIG["min_power_score"]:
                    stats["success_examples"] += 1

                    # åŸºæœ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
                    training_entry = {
                        "title": title,
                        "category": category,
                        "power_score": power_score,
                        "virality_score": note.get("virality_score", 0),
                        "analysis": asdict(analysis),
                        "user_nickname": note.get("user_nickname", ""),
                        "follower_count": note.get("follower_count", 0),
                        "like_count": note.get("like_count", 0),
                    }
                    training_data.append(training_entry)

                    # Evol-Instructå½¢å¼
                    variants = create_instruction_variants(
                        title, analysis, category, power_score
                    )
                    for variant in variants:
                        evol_instruct_data.append(variant)
                        stats["evol_instruct_count"] += 1

            except Exception as e:
                print(f"  âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
                continue

    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    with open(TRAINING_FILE, "w", encoding="utf-8") as f:
        for entry in training_data:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    with open(EVOL_INSTRUCT_FILE, "w", encoding="utf-8") as f:
        for entry in evol_instruct_data:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
    report = {
        "summary": {
            "total_raw": stats["total_raw"],
            "filtered_out": stats["filtered_out"],
            "success_examples": stats["success_examples"],
            "evol_instruct_count": stats["evol_instruct_count"],
        },
        "categories": dict(stats["categories"].most_common()),
        "patterns": dict(stats["patterns"].most_common()),
        "difficulties": dict(stats["difficulties"]),
    }

    with open(QUALITY_REPORT_FILE, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š å‡¦ç†çµæœ:")
    print(f"  - ç”Ÿãƒ‡ãƒ¼ã‚¿: {stats['total_raw']}ä»¶")
    print(f"  - ãƒ•ã‚£ãƒ«ã‚¿é™¤å¤–: {stats['filtered_out']}ä»¶")
    print(f"  - æˆåŠŸä¾‹: {stats['success_examples']}ä»¶")
    print(f"  - Evol-Instructå½¢å¼: {stats['evol_instruct_count']}ä»¶")

    print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  - {TRAINING_FILE}")
    print(f"  - {EVOL_INSTRUCT_FILE}")
    print(f"  - {QUALITY_REPORT_FILE}")

    print("\n" + "=" * 60)
    print("âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†!")
    print("=" * 60)

# ============================================================
# ãƒ¡ã‚¤ãƒ³
# ============================================================

if __name__ == "__main__":
    process_data()
