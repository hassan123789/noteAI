# Qwen3 æ·±å±¤ãƒªã‚µãƒ¼ãƒè£œè¶³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

> WORLD_CLASS_FINETUNING_STANDARDS.md ã®è£œè¶³è³‡æ–™
>
> **ä½œæˆæ—¥**: 2025å¹´1æœˆ
> **ç›®çš„**: å¾¹åº•çš„ãªWebãƒªã‚µãƒ¼ãƒã§ç™ºè¦‹ã—ãŸQwen3ç‰¹æœ‰ã®å•é¡Œã¨å¯¾ç­–

---

## ğŸš¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: Qwen3ç‰¹æœ‰ã®å•é¡Œã¨å¯¾ç­–ï¼ˆè¶…é‡è¦ï¼‰

### Qwen Tokenizerã®ç‰¹æ®Šæ€§

**ã‚½ãƒ¼ã‚¹**: Qwenå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆqwen.readthedocs.ioï¼‰

| ãƒˆãƒ¼ã‚¯ãƒ³ | å½¹å‰² | æ³¨æ„ç‚¹ |
|----------|------|--------|
| `<\|im_start\|>` | ã‚¿ãƒ¼ãƒ³é–‹å§‹ï¼ˆbot tokenï¼‰ | å„ã‚¿ãƒ¼ãƒ³ã®å…ˆé ­ã«å¿…é ˆ |
| `<\|im_end\|>` | ã‚¿ãƒ¼ãƒ³çµ‚äº†ï¼ˆeot tokenï¼‰ | **ã“ã‚ŒãŒEOSæ‰±ã„** |
| `<\|endoftext\|>` | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçµ‚äº†ï¼ˆeod tokenï¼‰ | ä¼šè©±çµ‚äº†æ™‚ã«è¿½åŠ ã•ã‚Œã‚‹ |

### âš ï¸ è¶…é‡è¦: Qwenã®eos_tokenå•é¡Œ

Qwenå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚ˆã‚Š:
> "Qwen does not append a fixed token to each packed training sequence. However, as most frameworks do not have the concept of eot and use eos instead for stopping criteria in inference, **eos token is set to eot for Qwen**."

**ã¤ã¾ã‚Š**:

- Qwenã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `eos_token` ã‚’æŒãŸãªã„
- ã—ã‹ã—æ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ `eos_token` ã§åœæ­¢åˆ¤å®š
- Qwenã§ã¯ `<|im_end|>` ãŒ `eos_token` ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹
- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã“ã®è¨­å®šãŒå£Šã‚Œã‚‹ã¨**ç„¡é™ç”Ÿæˆ**ã‚„**ã‚´ãƒŸå‡ºåŠ›**

### ChatMLå½¢å¼ï¼ˆQwenå¿…é ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰

```
<|im_start|>system
{ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ}<|im_end|>
<|im_start|>user
{ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›}<|im_end|>
<|im_start|>assistant
{ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›}<|im_end|>
```

**Qwen3ã‹ã‚‰ã®å¤‰æ›´ç‚¹**:

- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‰Šé™¤ã•ã‚ŒãŸ
- 151,646ãƒˆãƒ¼ã‚¯ãƒ³ã®å¤§è¦æ¨¡ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼

### æ—¢çŸ¥ã®Qwen3å•é¡Œï¼ˆGitHub Issuesèª¿æŸ»çµæœï¼‰

| Issue | å•é¡Œ | åŸå›  | å¯¾ç­– |
|-------|------|------|------|
| **llama.cpp #13310** | Qwen3ãŒ"GGGGG..."ã‚´ãƒŸå‡ºåŠ› | ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒŸã‚¹ãƒãƒƒãƒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ | æ­£ç¢ºãªChatMLãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä½¿ç”¨ |
| **Axolotl #2073** | ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã«`<\|im_end\|>`ã‚’ç”Ÿæˆã§ããªã„ â†’ ã‚´ãƒŸå‡ºåŠ› | EOSè¨­å®šä¸å‚™ | tokenizerè¨­å®šã‚’æ˜ç¤ºçš„ã«ç¢ºèª |
| **Unsloth #2405** | é•·ã„å…¥åŠ›ã§ã‚´ãƒŸå‡ºåŠ› | ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¶…é | max_seq_lengthèª¿æ•´ |
| **Unsloth #1333** | Qwen 2.5ã§train_on_responses_onlyã‚¨ãƒ©ãƒ¼ | Triton AssertionError | Unslothãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª |

### Axolotl #2073 ã®è©³ç´°ï¼ˆnoteAIå¤±æ•—ã¨é¡ä¼¼ï¼‰

å ±å‘Šå†…å®¹:
> "Qwen 2.5 Base unable to generate `<|im_end|>` even after finetuning"
> "Model generates answer then gibberish: 'The answer is: 11 prostituerade...11VRTX...'"

**ã“ã‚Œã¯noteAI v1ã®ç—‡çŠ¶ã¨é…·ä¼¼ï¼**

- å›ç­”ã‚’å‡ºåŠ›å¾Œã«ã‚´ãƒŸæ–‡å­—
- `<|im_end|>`ã‚’ç”Ÿæˆã§ããªã„ = åœæ­¢ã§ããªã„

### Unsloth train_on_responses_onlyè¨­å®šï¼ˆQwenç”¨ï¼‰

**æ­£ç¢ºãªè¨­å®š**:

```python
from unsloth.chat_templates import train_on_responses_only

trainer = train_on_responses_only(
    trainer,
    instruction_part = "<|im_start|>user\n",
    response_part = "<|im_start|>assistant\n",
)
```

âš ï¸ **æ”¹è¡Œã®ä½ç½®ã«æ³¨æ„**ï¼`\n`ã®æœ‰ç„¡ã§å‹•ä½œãŒå¤‰ã‚ã‚‹

HuggingFace Spaceã§äº‹å‰ãƒ†ã‚¹ãƒˆå¯èƒ½:

- train_on_responses_onlyæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹SpaceãŒå­˜åœ¨
- ãƒ¢ãƒ‡ãƒ«IDã‚’å…¥åŠ›ã—ã¦æ­£ã—ãå‹•ä½œã™ã‚‹ã‹ç¢ºèªå¯èƒ½

### Qwenå°‚ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] `eos_token` ãŒ `<|im_end|>` ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹
- [ ] è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã« `<|im_end|>` ãŒæ­£ã—ãå«ã¾ã‚Œã¦ã„ã‚‹ã‹
- [ ] ChatMLãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ­£ç¢ºã«å®ˆã‚‰ã‚Œã¦ã„ã‚‹ã‹
- [ ] `train_on_responses_only` ã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒæ­£ã—ã„ã‹
- [ ] `max_seq_length` ãŒé©åˆ‡ã‹ï¼ˆé•·ã™ãã‚‹å…¥åŠ›ã§ã‚´ãƒŸå‡ºåŠ›ï¼‰
- [ ] Qwen3ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‰Šé™¤ã‚’è€ƒæ…®ã—ã¦ã„ã‚‹ã‹

---

## ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: LoRA Rank/Alpha ã®æ·±ã„ç†è§£

### Alpha/Rank æ¯”ç‡ã®çœŸå®Ÿ

**ã‚½ãƒ¼ã‚¹**: Reddit r/LocalLLaMAã€DataScience StackExchangeã€Thinking Machines Blog

| è¨­å®š | åŠ¹æœ | æ¨å¥¨ |
|------|------|------|
| alpha = rank | æ¨™æº–çš„ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° | âœ… æ¨å¥¨ |
| alpha < rank | ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹æœãŒ**å¼·ã¾ã‚‹** | æ³¨æ„å¿…è¦ |
| alpha > rank | ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹æœãŒ**å¼±ã¾ã‚‹** | å ´åˆã«ã‚ˆã‚‹ |
| alpha = 16ï¼ˆå›ºå®šï¼‰ | å…ƒã®LoRAè«–æ–‡ã®æ¨å¥¨ | ä¿å®ˆçš„ |

Reddit r/LocalLLaMaã‚ˆã‚Š:
> "Decreasing alpha relative to rank increases the effect of fine-tuning. Increasing alpha relative to rank decreases it."

DataScience StackExchangeã‚ˆã‚Š:
> "Alpha scales the learned weights. Existing literature, including the original LoRA paper, generally advises fixing Alphaâ€”often at 16â€”rather than tuning it."

### LoRA Without Regretï¼ˆæœ€æ–°ç ”ç©¶ 2025ï¼‰

**ã‚½ãƒ¼ã‚¹**: Thinking Machines Lab Blog

> "LoRA can match Full Fine-Tuning when you set it up correctly"

é‡è¦ãªç™ºè¦‹:

1. **LoRAã®æœ€é©LRã¯Full FTã®10å€**
2. **rank > 256ã¯åŠ¹æœè–„**ï¼ˆå®¹é‡åˆ¶ç´„ãŒãªããªã‚‹ï¼‰
3. **MLP/MoEãƒ–ãƒ­ãƒƒã‚¯ã«ã‚¢ãƒ€ãƒ—ã‚¿é…ç½®ã§æœ€å¤§åŠ¹æœ**
4. **å¼·åŒ–å­¦ç¿’ã§ã¯rank=1ã§ã‚‚Full FTã¨åŒç­‰**
5. **LoRAã¯å°ã€œä¸­è¦æ¨¡ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€ã‚‚åŠ¹æœçš„**

### noteAIå‘ã‘LoRAè¨­å®šï¼ˆæœ€çµ‚æ¨å¥¨ï¼‰

```python
lora_config = {
    "r": 32,           # rankï¼ˆå•é¡Œãªã—ï¼‰
    "lora_alpha": 64,  # alpha = rank Ã— 2ï¼ˆå•é¡Œãªã—ï¼‰
    "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj",
                       "gate_proj", "up_proj", "down_proj"],
    "lora_dropout": 0.0,  # å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯0.05ã‚‚æ¤œè¨
    "use_rslora": True,   # rsLoRAæ¨å¥¨
}
```

**çµè«–**: noteAI v1ã®LoRAè¨­å®šè‡ªä½“ã¯é©æ­£ã€‚å•é¡Œã¯ãƒ‡ãƒ¼ã‚¿å“è³ªã¨EOSè¨­å®šã€‚

---

## ğŸ”„ ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: GGUFå¤‰æ›ã®è½ã¨ã—ç©´

### æ—¢çŸ¥ã®å•é¡Œï¼ˆGitHub Issuesåé›†ï¼‰

| Issue | å•é¡Œ | å¯¾ç­– |
|-------|------|------|
| **llama.cpp #7062** | LoRAãƒãƒ¼ã‚¸å¾Œã®GGUFå¤‰æ›ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒ**ãƒ©ãƒ³ãƒ€ãƒ ã«æ¬ è½** | HFã§å‹•ä½œç¢ºèªã—ã¦ã‹ã‚‰å¤‰æ› |
| **Unsloth #611** | `save_pretrained_merged`ãŒå®Ÿéš›ã«ã¯ãƒãƒ¼ã‚¸ã—ãªã„ï¼ˆadapter_model.binã ã‘ä¿å­˜ï¼‰ | `merge_and_unload(safe_merge=True)`ä½¿ç”¨ |
| **Unsloth #3091** | bfloat16ã§ã®ãƒãƒ¼ã‚¸ç²¾åº¦å•é¡Œ | safe_merge=Trueä½¿ç”¨ |
| **HuggingFace Discussion** | GGUFå¤‰æ›å¾Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ | F16ã§æ¯”è¼ƒãƒ†ã‚¹ãƒˆ |

### llama.cpp #7062 ã®é‡è¦ãªå ±å‘Š

> "GGUF conversion of the merged model does not produce the same output. The GGUF has lost some of its fine tune data, while still maintaining most of it."
> "I've tried F16, Q8, same issues. This is not a quantization issue."

**ã¤ã¾ã‚Š**: GGUFå¤‰æ›è‡ªä½“ãŒãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’æå¤±ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼

### å®‰å…¨ãªGGUFå¤‰æ›æ‰‹é †

```python
# Step 1: LoRAãƒãƒ¼ã‚¸ï¼ˆsafe_merge=Trueæ¨å¥¨ï¼‰
merged_model = model.merge_and_unload(safe_merge=True)

# Step 2: HuggingFaceå½¢å¼ã§ä¿å­˜
merged_model.save_pretrained("merged_model_16bit")
tokenizer.save_pretrained("merged_model_16bit")

# Step 3: HFå½¢å¼ã§æ¨è«–ãƒ†ã‚¹ãƒˆï¼ˆå¿…é ˆï¼ï¼‰
# ã“ã“ã§å•é¡ŒãŒã‚ã‚Œã°GGUFå¤‰æ›ã«é€²ã¾ãªã„

# Step 4: llama.cppã§GGUFå¤‰æ›
# python convert_hf_to_gguf.py merged_model_16bit --outtype f16

# Step 5: F16 GGUFã§æ¨è«–ãƒ†ã‚¹ãƒˆ

# Step 6: é‡å­åŒ–
# llama-quantize model.f16.gguf model.Q4_K_M.gguf Q4_K_M
```

### bfloat16 ãƒãƒ¼ã‚¸å•é¡Œï¼ˆUnsloth #3091ï¼‰

PyTorch #115144ã§å ±å‘Šã•ã‚ŒãŸå•é¡Œ:

- `nn.Linear` in bfloat16 â‰  `weight @ input + bias` in bfloat16
- æ¼”ç®—é †åºãŒbfloat16ç²¾åº¦ã«å½±éŸ¿
- LoRAé‡ã¿ã¯float32ã€ãƒ™ãƒ¼ã‚¹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯bfloat16 â†’ æ¼”ç®—é †åºã§çµæœãŒå¤‰ã‚ã‚‹
- `safe_merge=True` ã§ç·©å’Œå¯èƒ½

```python
# å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ï¼ˆsafe_merge=Falseï¼‰
delta_weight = self.get_delta_weight(active_adapter)
base_layer.weight.data += delta_weight

# æ­£ã—ã„ã‚³ãƒ¼ãƒ‰ï¼ˆsafe_merge=Trueï¼‰
delta_weight = self.get_delta_weight(active_adapter)
orig_weight += delta_weight.to(orig_dtype)
```

---

## âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³4: åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ‰‹æ³•

### æœ€æ–°æ‰‹æ³•æ¯”è¼ƒï¼ˆ2024-2025ï¼‰

**ã‚½ãƒ¼ã‚¹**: TACLè«–æ–‡ã€arXivã€GitHub Awesome-LLM-Synthetic-Data

| æ‰‹æ³• | èª¬æ˜ | åŠ¹æœ | ã‚½ãƒ¼ã‚¹ |
|------|------|------|--------|
| **Self-Instruct** | LLMãŒè‡ªå·±ç”Ÿæˆ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | Wang et al., 2023 |
| **Evol-Instruct** | æŒ‡ç¤ºã‚’é€²åŒ–ã•ã›ã‚‹ | Self-Instructã‚ˆã‚Šä¸Š | Xu et al., 2023 |
| **CRAFT** | ã‚³ãƒ¼ãƒ‘ã‚¹æ¤œç´¢+ç”Ÿæˆ | Evol-Instructè¶…ãˆ | TACL 2024 |
| **CoT-Self-Instruct** | CoTæ¨è«–ä»˜ãç”Ÿæˆ | æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªç§€ | Meta FAIR, 2025 |

### CRAFTè«–æ–‡ã®é‡è¦ãªç™ºè¦‹

> "CRAFT not only outperforms other fully synthetic data generation methods, such as Self-Instruct and Evol-Instruct, but also exhibits robustness to variations in the quality of the initial few shots."

ã¤ã¾ã‚Š:

- CRAFTã¯åˆæœŸfew-shotã®å“è³ªå¤‰å‹•ã«å¼·ã„
- ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«æœ€é©
- äººé–“ãŒã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½

### noteAIå‘ã‘åˆæˆãƒ‡ãƒ¼ã‚¿æˆ¦ç•¥

```
[æ—¢å­˜é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ 500ä»¶]
    â†“
[GPT-4ç­‰ã§å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°]
    â†“
[ä¸Šä½ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚·ãƒ¼ãƒ‰]
    â†“
[CRAFTã¾ãŸã¯Evol-Instructé©ç”¨]
    â†“
[åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ 1000-2000ä»¶]
    â†“
[å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°]
    â†“
[æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ]
```

---

## ğŸ›¡ï¸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³5: éå­¦ç¿’æ¤œå‡ºã®å®Ÿè£…

### EarlyStoppingCallbackä½¿ç”¨æ–¹æ³•

**ã‚½ãƒ¼ã‚¹**: HuggingFace Discussionsã€philschmid.de

```python
from transformers import EarlyStoppingCallback

trainer = SFTTrainer(
    model=model,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,  # å¿…é ˆï¼
    args=TrainingArguments(
        evaluation_strategy="steps",
        eval_steps=50,
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
    ),
    callbacks=[
        EarlyStoppingCallback(early_stopping_patience=3)
    ],
)
```

### éå­¦ç¿’æ¤œå‡ºã‚µã‚¤ãƒ³ï¼ˆå­¦è¡“ç ”ç©¶ãƒ™ãƒ¼ã‚¹ï¼‰

**ã‚½ãƒ¼ã‚¹**: Redditã€Kaggleã€arXiv

```
ğŸš¨ ç¢ºå®Ÿãªéå­¦ç¿’ã‚µã‚¤ãƒ³:
1. Train Lossâ†“ + Val Lossâ†‘ = éå­¦ç¿’
2. Train Lossç•°å¸¸ã«ä½ã„ï¼ˆ< 0.3ï¼‰
3. å‡ºåŠ›ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ç¹°ã‚Šè¿”ã—
4. æ–°è¦å…¥åŠ›ã«å¯¾ã—ã¦ã‚´ãƒŸ or ç„¡é™ãƒ«ãƒ¼ãƒ—

ğŸ“Š noteAI v1ã®ç—‡çŠ¶ï¼ˆå®Œå…¨ä¸€è‡´ï¼‰:
- Loss: 2.847 â†’ 0.254 (91%æ¸›å°‘) â† ç•°å¸¸ã«ä½ã„
- Val Lossãªã— â† æ¤œå‡ºä¸èƒ½
- å‡ºåŠ›: ã€Œã€ã€ã€ã€ã€ã€ã€ã€ã€ â† éå­¦ç¿’ã®å…¸å‹ç—‡çŠ¶
```

Reddit r/MachineLearningã‚ˆã‚Š:
> "If train keeps going down but test goes up you're over[fitting]"

Kaggleã‚¬ã‚¤ãƒ‰ã‚ˆã‚Š:
> "Training loss goes down, but validation loss goes UP = Overfitting (model memorizing, not learning)"

---

## ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³6: æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆç©¶æ¥µç‰ˆï¼‰

### ğŸ”´ çµ¶å¯¾ã«å®ˆã‚‹ã¹ãé …ç›®ï¼ˆã“ã‚Œã‚’ç ´ã‚‹ã¨å¤±æ•—ï¼‰

1. **ãƒ‡ãƒ¼ã‚¿å“è³ª100%**: ã‚¿ã‚°å½¢å¼ãƒ»ã‚´ãƒŸãƒ‡ãƒ¼ã‚¿0%
2. **Validationåˆ†å‰²**: æœ€ä½80/20
3. **HFæ¨è«–ãƒ†ã‚¹ãƒˆ**: GGUFå¤‰æ›å‰ã«å¿…é ˆ
4. **EOSè¨­å®šç¢ºèª**: Qwenã§ã¯`<|im_end|>`ãŒ`eos_token`
5. **ã‚¨ãƒãƒƒã‚¯1-3**: ãã‚Œä»¥ä¸Šã¯éå­¦ç¿’

### ğŸŸ¡ å¼·ãæ¨å¥¨ï¼ˆç ´ã‚‹ã¨å“è³ªä½ä¸‹ï¼‰

1. **train_on_responses_only**: 2-5%ç²¾åº¦å‘ä¸Š
2. **rsLoRA**: Trueæ¨å¥¨
3. **Cosine Scheduler**: åæŸå®‰å®š
4. **Early Stopping**: patience 3-5
5. **safe_merge=True**: ãƒãƒ¼ã‚¸æ™‚

### ğŸŸ¢ æ¨å¥¨ï¼ˆã•ã‚‰ãªã‚‹æ”¹å–„ï¼‰

1. **åˆæˆãƒ‡ãƒ¼ã‚¿å¢—å¼·**: CRAFTã¾ãŸã¯Evol-Instruct
2. **LLM-as-Judgeè©•ä¾¡**: GPT-4ã§ã‚¿ã‚¤ãƒˆãƒ«å“è³ªè©•ä¾¡
3. **A/Bãƒ†ã‚¹ãƒˆ**: å®Ÿé‹ç”¨ã§ã®æœ€çµ‚æ¤œè¨¼

---

## ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³7: noteAI v2 å®Ÿè£…è¨ˆç”»

### Step 1: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

```python
# data/processed/evol_instruct_data.jsonl ã‹ã‚‰
# 1. ã‚¿ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé™¤å»ï¼ˆ28%ï¼‰
# 2. é‡è¤‡é™¤å»
# 3. 80/20 Train/Valåˆ†å‰²
```

### Step 2: è¨“ç·´è¨­å®š

```python
training_args = TrainingArguments(
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    num_train_epochs=1,  # ã¾ãš1ã‚¨ãƒãƒƒã‚¯
    learning_rate=2e-4,
    lr_scheduler_type="cosine",
    warmup_steps=5,
    evaluation_strategy="steps",
    eval_steps=20,
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
)

callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]
```

### Step 3: æ¤œè¨¼ãƒ—ãƒ­ã‚»ã‚¹

```
[è¨“ç·´å®Œäº†]
    â†“
[HFå½¢å¼ã§5-10ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆ] â† æœ€é‡è¦ï¼
    â†“ å•é¡Œã‚ã‚Šâ†’ãƒ‡ãƒ¼ã‚¿/è¨­å®šè¦‹ç›´ã—
[F16 GGUFå¤‰æ›]
    â†“
[F16ã§æ¨è«–ãƒ†ã‚¹ãƒˆ]
    â†“ å•é¡Œã‚ã‚Šâ†’å¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
[Q4_K_Mé‡å­åŒ–]
    â†“
[æœ€çµ‚ãƒ†ã‚¹ãƒˆ]
```

---

## ğŸ” ã‚»ã‚¯ã‚·ãƒ§ãƒ³8: v1å¤±æ•—ã®æœ€çµ‚è¨ºæ–­

### å…¨ã¦ã®è¨¼æ‹ ã‚’è¸ã¾ãˆãŸçµè«–

| è¦³å¯Ÿã•ã‚ŒãŸç—‡çŠ¶ | å¯èƒ½ãªåŸå›  | ç¢ºåº¦ |
|----------------|-----------|------|
| ã€Œã€ã€ã€ã€ã€ç¹°ã‚Šè¿”ã— | éå­¦ç¿’ / EOSå•é¡Œ | é«˜ |
| F16ã§ã‚‚Q4ã§ã‚‚åŒã˜ç—‡çŠ¶ | é‡å­åŒ–ã¯åŸå› ã§ã¯ãªã„ | ç¢ºå®š |
| Loss 91%æ¸›å°‘ | éå­¦ç¿’ã®ç–‘ã„ | é«˜ |
| ãƒ‡ãƒ¼ã‚¿28%æ±šæŸ“ | ãƒ¢ãƒ‡ãƒ«ãŒã‚´ãƒŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ | é«˜ |
| Valåˆ†å‰²ãªã— | éå­¦ç¿’æ¤œå‡ºä¸èƒ½ | ç¢ºå®š |

### æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„æ ¹æœ¬åŸå› ï¼ˆè¤‡åˆè¦å› ï¼‰

1. **ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œ**: 28%ã®ã‚¿ã‚°å½¢å¼ãƒ‡ãƒ¼ã‚¿ãŒãƒ¢ãƒ‡ãƒ«ã‚’æ±šæŸ“
2. **éå­¦ç¿’**: Loss 0.254ã¾ã§ä¸‹ãŒã‚‹ã®ã¯ç•°å¸¸ + Valç›£è¦–ãªã—
3. **EOSè¨­å®šå•é¡Œ**: `<|im_end|>`ãŒæ­£ã—ãå­¦ç¿’ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§
4. **GGUFå¤‰æ›å•é¡Œ**: llama.cpp #7062ã®ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿æ¬ è½ã—ãŸå¯èƒ½æ€§

### v2ã§ç¢ºå®Ÿã«æˆåŠŸã™ã‚‹ãŸã‚ã®å„ªå…ˆé †ä½

```
ã€æœ€å„ªå…ˆã€‘
1. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆã‚¿ã‚°å½¢å¼0%ï¼‰
2. Train/Valåˆ†å‰²ï¼ˆ80/20ï¼‰
3. HFæ¨è«–ãƒ†ã‚¹ãƒˆå®Ÿæ–½

ã€é«˜å„ªå…ˆã€‘
4. ã‚¨ãƒãƒƒã‚¯æ•°å‰Šæ¸›ï¼ˆ3â†’1ï¼‰
5. EarlyStoppingCallbackå°å…¥
6. EOSè¨­å®šç¢ºèª

ã€æ¨å¥¨ã€‘
7. safe_merge=Trueä½¿ç”¨
8. F16æ®µéšã§ãƒ†ã‚¹ãƒˆ
```

---

*ä½œæˆæ—¥: 2025å¹´1æœˆ*
*èª¿æŸ»ç¯„å›²: Qwenå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€GitHub Issues (llama.cpp, Unsloth, Axolotl)ã€å­¦è¡“è«–æ–‡ (TACL, arXiv)ã€Reddit (r/LocalLLaMA, r/MachineLearning)ã€Stack Exchangeã€Thinking Machines Lab*
