"""
noteAI ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - ä¸–ç•Œæœ€é«˜æ°´æº–ç‰ˆ
==================================================

ğŸ“Š èª¿æŸ»ãƒ™ãƒ¼ã‚¹:
- note.com 10ä¸‡ä»¶è¨˜äº‹åˆ†æï¼ˆã‚¹ã‚­æ•°+8%ã«ãªã‚‹ã‚¿ã‚¤ãƒˆãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
- noteå…¬å¼ã€Œä»Šæ—¥ã®æ³¨ç›®è¨˜äº‹ã€3,900ä»¶åˆ†æ
- ACL 2025 LLMãƒ‡ãƒ¼ã‚¿å¤šæ§˜æ€§ç ”ç©¶
- Latitude.so ãƒ‡ãƒ¼ã‚¿ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

ğŸ¯ æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆ:
- æŠ•è³‡ãƒ»ãƒãƒãƒ¼ç³»ï¼ˆnoteæœ€äººæ°—ã‚¸ãƒ£ãƒ³ãƒ«ï¼‰ã‚’æ–°è¦è¿½åŠ 
- ãƒ©ã‚¤ãƒ•ãƒãƒƒã‚¯æ‹¡å¼µï¼ˆãƒã‚ºã‚‹ã€Œâ—‹ã¤ã®æ–¹æ³•ã€ãƒ‘ã‚¿ãƒ¼ãƒ³åé›†ï¼‰
- ã‚«ãƒ†ã‚´ãƒªæ¯”ç‡ã‚’LLMå¤šæ§˜æ€§ç ”ç©¶ã«åŸºã¥ãæœ€é©åŒ–
"""

import csv
import json
import os
import time
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import requests

# ============================================================
# ä¸–ç•Œæœ€é«˜æ°´æº–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼ˆ2024-2025ãƒªã‚µãƒ¼ãƒçµæœï¼‰
# ============================================================

# note.comå®Ÿè¨¼ãƒ‡ãƒ¼ã‚¿ + LLMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¤šæ§˜æ€§è¦ä»¶ã«åŸºã¥ã
SEARCH_KEYWORDS = {
    # ============================================================
    # ğŸ¥‡ 1ä½: æŠ•è³‡ãƒ»ãƒãƒãƒ¼ç³»ï¼ˆnoteæœ€äººæ°—: å¹³å‡ãƒ“ãƒ¥ãƒ¼150-300ï¼‰
    # ç ”ç©¶çµæœ: å…·ä½“çš„ãªé‡‘é¡ã‚’å«ã‚€ã‚¿ã‚¤ãƒˆãƒ«ãŒã‚¹ã‚­+8%
    # ============================================================
    "money_invest": [
        # NISAãƒ»æŠ•è³‡ï¼ˆnoteäººæ°—ãƒˆãƒƒãƒ—ï¼‰
        "NISA", "ã¤ã¿ãŸã¦NISA", "æ–°NISA", "æŠ•è³‡åˆå¿ƒè€…", "è³‡ç”£é‹ç”¨",
        "æŠ•è³‡ä¿¡è¨—", "æ ªå¼æŠ•è³‡", "é…å½“é‡‘", "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æŠ•è³‡",
        # ç¯€ç´„ãƒ»å®¶è¨ˆ
        "ç¯€ç´„è¡“", "å›ºå®šè²»å‰Šæ¸›", "å¹´é–“â—‹ä¸‡å††æµ®ã„ãŸ", "ãŠé‡‘ã®å¢—ã‚„ã—æ–¹",
        "å®¶è¨ˆæ”¹å–„", "ã‚³ã‚¹ãƒ‘", "ã‚µãƒ–ã‚¹ã‚¯è¦‹ç›´ã—",
        # å…·ä½“çš„é‡‘é¡ï¼ˆãƒã‚ºã‚Šã‚„ã™ã„ï¼‰
        "æœˆ1ä¸‡å††", "å¹´é–“10ä¸‡å††", "1800ä¸‡å††", "100ä¸‡å††",
    ],

    # ============================================================
    # ğŸ¥ˆ 2ä½: è‡ªå·±å•“ç™ºãƒ»å¿ƒç†å­¦ãƒ»å“²å­¦ï¼ˆå¹³å‡ãƒ“ãƒ¥ãƒ¼120-200ï¼‰
    # ã‚ãªãŸã®å¼·ã¿: ã€Œå¤‰ã‚ã‚ŒãŸç†ç”±ã€ã€Œç¿’æ…£åŒ–ã€
    # ============================================================
    "selfhelp_philosophy": [
        # ç¿’æ…£ãƒ»è¡Œå‹•ç§‘å­¦
        "ç¿’æ…£åŒ–", "ä¸‰æ—¥åŠä¸»", "ç¶™ç¶š", "ç¶šã‹ãªã„", "å¤‰ã‚ã‚ŒãŸ",
        "é ‘å¼µã‚‰ãªã„", "ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³", "æœæ´»", "è¡Œå‹•ç§‘å­¦",
        # å¿ƒç†å­¦ï¼ˆnoteäººæ°—ï¼‰
        "å¿ƒç†å­¦", "ãƒ¡ãƒ³ã‚¿ãƒ«", "ãƒã‚¤ãƒ³ãƒ‰ã‚»ãƒƒãƒˆ", "è‡ªå·±è‚¯å®šæ„Ÿ",
        "ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚„ã‚‹æ°—", "å…ˆå»¶ã°ã—", "å®Œç’§ä¸»ç¾©",
        # å“²å­¦ãƒ»ç”Ÿãæ–¹ï¼ˆã‚ãªãŸãŒå¥½ãï¼‰
        "å“²å­¦", "æ€è€ƒæ³•", "ä¾¡å€¤è¦³", "äººç”Ÿè¦³", "ç”Ÿãæ–¹",
        "æœ¬è³ª", "æ„å‘³", "é¸æŠ", "æ±ºæ–­", "å¾Œæ‚”",
        # æ°—ã¥ãç³»ï¼ˆãƒã‚ºã‚Šã‚„ã™ã„ï¼‰
        "æ°—ã¥ã„ãŸ", "ã‚ã‹ã£ãŸ", "ã ã£ãŸ", "å®Ÿã¯", "æœ¬å½“ã¯",
        # ç¤¾ä¼šè€ƒå¯Ÿ
        "æ—¥æœ¬äºº", "å¸¸è­˜", "æ™®é€š", "ãªãœ", "ä»•çµ„ã¿",
    ],

    # ============================================================
    # ğŸ¥‰ 3ä½: AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ï¼ˆå¹³å‡ãƒ“ãƒ¥ãƒ¼80-150ã€æˆé•·ä¸­ï¼‰
    # ã‚ãªãŸã®ãƒ¡ã‚¤ãƒ³ã‚¸ãƒ£ãƒ³ãƒ«
    # ============================================================
    "ai_tech": [
        # ãƒ­ãƒ¼ã‚«ãƒ«AIãƒ»ç”»åƒç”Ÿæˆï¼ˆã‚ãªãŸã®å°‚é–€ï¼‰
        "ãƒ­ãƒ¼ã‚«ãƒ«AI", "Stable Diffusion", "ComfyUI", "ç”»åƒç”ŸæˆAI",
        "AIã‚¤ãƒ©ã‚¹ãƒˆ", "ç”ŸæˆAI", "FLUX", "LoRA",
        # ChatGPTãƒ»LLMï¼ˆnoteæ€¥æˆé•·ï¼‰
        "ChatGPT", "ChatGPTæ´»ç”¨", "Claude", "Copilot", "LLM",
        "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", "AIåŠ¹ç‡åŒ–", "AIã§æ™‚çŸ­",
        # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°
        "Python", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°åˆå¿ƒè€…", "VSCode", "GitHub",
        # è„³ç§‘å­¦ãƒ»æœªæ¥æŠ€è¡“
        "è„³ç§‘å­¦", "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "BCI",
        # å…·ä½“çš„æ™‚çŸ­ï¼ˆãƒã‚ºã‚‹ï¼‰
        "40æ™‚é–“â†’3æ™‚é–“", "â—‹æ™‚é–“çŸ­ç¸®", "è‡ªå‹•åŒ–",
    ],

    # ============================================================
    # 4ä½: ãƒ©ã‚¤ãƒ•ãƒãƒƒã‚¯ãƒ»å®Ÿç”¨ï¼ˆã€Œâ—‹ã¤ã®æ–¹æ³•ã€ãƒ‘ã‚¿ãƒ¼ãƒ³åé›†ï¼‰
    # ============================================================
    "lifehack": [
        # æ™‚çŸ­ãƒ»åŠ¹ç‡åŒ–
        "æ™‚çŸ­", "åŠ¹ç‡åŒ–", "ç”Ÿç”£æ€§", "æ•´ç†è¡“",
        # ãƒŸãƒ‹ãƒãƒªã‚ºãƒ ï¼ˆnoteäººæ°—ï¼‰
        "ãƒŸãƒ‹ãƒãƒªã‚¹ãƒˆ", "æ–­æ¨é›¢", "ã‚·ãƒ³ãƒ—ãƒ«ãƒ©ã‚¤ãƒ•",
        # æ–¹æ³•ç³»ï¼ˆãƒã‚ºã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        "â—‹ã¤ã®æ–¹æ³•", "â—‹ã¤ã®ã‚³ãƒ„", "â—‹ã‚¹ãƒ†ãƒƒãƒ—",
        "åˆå¿ƒè€…å‘ã‘", "å®Œå…¨ã‚¬ã‚¤ãƒ‰", "å…¥é–€",
        # æœæ´»ãƒ»ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³
        "æœã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³", "å¤œã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³", "1æ—¥ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«",
    ],

    # ============================================================
    # 5ä½: ã‚¨ãƒ³ã‚¿ãƒ¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå¤šæ§˜æ€§ç¢ºä¿ï¼‰
    # ============================================================
    "entertainment": [
        # Netflixãƒ»ãƒ‰ãƒ©ãƒï¼ˆã‚ãªãŸã®è¨˜äº‹ã«ã‚ã‚Šï¼‰
        "Netflix", "NetflixãŠã™ã™ã‚", "ãƒ‰ãƒ©ãƒãƒ¬ãƒ“ãƒ¥ãƒ¼", "æµ·å¤–ãƒ‰ãƒ©ãƒ",
        "ä¸€æ°—è¦‹", "æ˜ ç”»æ„Ÿæƒ³", "æ˜ ç”»è€ƒå¯Ÿ",
        # ã‚¢ãƒ‹ãƒ¡
        "ã‚¢ãƒ‹ãƒ¡è€ƒå¯Ÿ", "ã‚¢ãƒ‹ãƒ¡æ„Ÿæƒ³", "â—‹â—‹ã‚’è¦³ã¦",
        # æ¨ã—æ´»ï¼ˆnoteæ€¥æˆé•·ï¼‰
        "æ¨ã—æ´»", "æ¨ã—ã®è©±",
    ],

    # ============================================================
    # 6ä½: å‰¯æ¥­ãƒ»ã‚­ãƒ£ãƒªã‚¢ï¼ˆåç›ŠåŒ–è¨˜äº‹ã§äººæ°—ï¼‰
    # ============================================================
    "career_sidejob": [
        # å‰¯æ¥­ï¼ˆnoteäººæ°—ï¼‰
        "å‰¯æ¥­", "å‰¯æ¥­åˆå¿ƒè€…", "AIå‰¯æ¥­", "noteåç›ŠåŒ–",
        "â—‹ä¸‡å††ç¨¼ã„ã ", "æœˆ5ä¸‡å††", "åç›ŠåŒ–",
        # ã‚­ãƒ£ãƒªã‚¢
        "è»¢è·", "ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹", "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯",
        "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—", "æœªçµŒé¨“ã‹ã‚‰",
        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
        "DLsite", "FANZA", "ã‚³ã‚³ãƒŠãƒ©",
    ],
}

# ============================================================
# ã‚«ãƒ†ã‚´ãƒªåé›†æ¯”ç‡ï¼ˆLLMå¤šæ§˜æ€§ç ”ç©¶ã«åŸºã¥ãæœ€é©ãƒãƒ©ãƒ³ã‚¹ï¼‰
# ============================================================
CATEGORY_RATIO = {
    "money_invest": 0.20,        # 20% - noteæœ€äººæ°—ï¼ˆå¿…é ˆè¿½åŠ ï¼‰
    "selfhelp_philosophy": 0.25, # 25% - ã‚ãªãŸã®å¼·ã¿ + å“²å­¦
    "ai_tech": 0.25,             # 25% - ã‚ãªãŸã®ãƒ¡ã‚¤ãƒ³
    "lifehack": 0.10,            # 10% - ãƒ‘ã‚¿ãƒ¼ãƒ³åé›†
    "entertainment": 0.10,       # 10% - å¤šæ§˜æ€§ç¢ºä¿
    "career_sidejob": 0.10,      # 10% - åç›ŠåŒ–äººæ°—
}

# ============================================================
# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆç”Ÿæˆï¼ˆæ¯”ç‡ã«åŸºã¥ãé‡ã¿ä»˜ã‘ï¼‰
# ============================================================

# ã™ã¹ã¦ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆã‚«ãƒ†ã‚´ãƒªæ¯”ç‡ã‚’è€ƒæ…®ï¼‰
ALL_KEYWORDS = []
for category, keywords in SEARCH_KEYWORDS.items():
    ratio = CATEGORY_RATIO.get(category, 0.1)
    for kw in keywords:
        ALL_KEYWORDS.append((category, kw, ratio))

print(f"ğŸ“Š ä¸–ç•Œæœ€é«˜æ°´æº–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {len(ALL_KEYWORDS)}å€‹ ({len(SEARCH_KEYWORDS)}ã‚«ãƒ†ã‚´ãƒª)")
print(f"ğŸ“Š ã‚«ãƒ†ã‚´ãƒªæ¯”ç‡: {CATEGORY_RATIO}")

# ============================================================
# è¨­å®š
# ============================================================

BASE_URL = "https://note.com/api"

CONFIG = {
    "max_users": 200,           # ç›®æ¨™ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
    "max_followers": 3000,      # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ä¸Šé™ï¼ˆå°‘ã—ç·©ã‚ï¼‰
    "min_followers": 5,         # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ä¸‹é™
    "min_likes_per_article": 20,  # è¨˜äº‹ã‚ãŸã‚Šæœ€ä½ã„ã„ã­æ•°
    "power_score_threshold": 0.5,  # Power Scoreé–¾å€¤
    "request_delay": 1.5,       # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ï¼ˆç§’ï¼‰
    "max_retries": 3,           # ãƒªãƒˆãƒ©ã‚¤å›æ•°
    "articles_per_user": 30,    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ãŸã‚Šæœ€å¤§è¨˜äº‹æ•°
}

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
DATA_DIR = Path("data")
PROGRESS_FILE = DATA_DIR / "collection_progress_custom.json"
RAW_DATA_FILE = DATA_DIR / "raw_notes_custom.jsonl"
USERS_FILE = DATA_DIR / "collected_users_custom.json"

# HTTPãƒ˜ãƒƒãƒ€ãƒ¼
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "application/json",
    "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
    "Referer": "https://note.com/",
}


# ============================================================
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ============================================================

@dataclass
class NoteArticle:
    """è¨˜äº‹ãƒ‡ãƒ¼ã‚¿"""
    id: str
    title: str
    user_id: str
    user_name: str
    user_urlname: str
    like_count: int
    follower_count: int
    power_score: float
    category: str
    keyword: str
    body_preview: str
    published_at: str
    url: str


# ============================================================
# APIé–¢æ•°
# ============================================================

def api_request(url: str, params: dict = None) -> Optional[dict]:
    """APIãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
    for attempt in range(CONFIG["max_retries"]):
        try:
            response = requests.get(
                url,
                params=params,
                headers=HEADERS,
                timeout=30
            )

            if response.status_code == 200:
                return response.json()
            elif response.status_code == 403:
                print(f"  âš ï¸ 403 Forbidden - å¾…æ©Ÿä¸­...")
                time.sleep(10)
            elif response.status_code == 429:
                print(f"  âš ï¸ 429 Rate Limited - å¾…æ©Ÿä¸­...")
                time.sleep(30)
            else:
                print(f"  âš ï¸ Status {response.status_code}")

        except Exception as e:
            print(f"  âŒ Error: {e}")

        time.sleep(CONFIG["request_delay"] * (attempt + 1))

    return None


def search_notes(keyword: str, page: int = 1) -> List[dict]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è¨˜äº‹æ¤œç´¢"""
    url = f"{BASE_URL}/v3/searches"
    params = {
        "q": keyword,
        "size": 20,
        "start": (page - 1) * 20,
        "sort": "like_count",
        "context": "note",
    }

    result = api_request(url, params)
    if result and "data" in result:
        notes = result["data"].get("notes", {})
        return notes.get("contents", [])
    return []


def get_user_info(urlname: str) -> Optional[dict]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—"""
    url = f"{BASE_URL}/v2/creators/{urlname}"
    result = api_request(url)
    if result and "data" in result:
        return result["data"]
    return None


def get_user_notes(urlname: str, page: int = 1) -> List[dict]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜äº‹ä¸€è¦§å–å¾—"""
    url = f"{BASE_URL}/v2/creators/{urlname}/contents"
    params = {
        "kind": "note",
        "page": page,
        "per_page": 20,
    }

    result = api_request(url, params)
    if result and "data" in result:
        contents = result["data"].get("contents", [])
        return contents
    return []


# ============================================================
# ãƒ‡ãƒ¼ã‚¿åé›†
# ============================================================

def calculate_power_score(like_count: int, follower_count: int) -> float:
    """Power Scoreè¨ˆç®—"""
    if follower_count == 0:
        return 0.0
    return round(like_count / follower_count, 3)


def collect_data():
    """ãƒ¡ã‚¤ãƒ³åé›†å‡¦ç†"""
    DATA_DIR.mkdir(exist_ok=True)

    # é€²æ—èª­ã¿è¾¼ã¿
    collected_users = set()
    if USERS_FILE.exists():
        with open(USERS_FILE, "r", encoding="utf-8") as f:
            collected_users = set(json.load(f))

    total_articles = 0

    print("\n" + "="*60)
    print("ğŸš€ noteAI ä¸–ç•Œæœ€é«˜æ°´æº–ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
    print("="*60)
    print(f"ğŸ“Š ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {len(ALL_KEYWORDS)}å€‹")
    print(f"ğŸ“Š ã‚«ãƒ†ã‚´ãƒª: {list(SEARCH_KEYWORDS.keys())}")
    print(f"ğŸ“Š ã‚«ãƒ†ã‚´ãƒªæ¯”ç‡: {CATEGORY_RATIO}")
    print(f"ğŸ“Š åé›†æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼: {len(collected_users)}äºº")
    print("="*60 + "\n")

    with open(RAW_DATA_FILE, "a", encoding="utf-8") as f:
        for idx, (category, keyword, ratio) in enumerate(ALL_KEYWORDS):
            print(f"\n[{idx+1}/{len(ALL_KEYWORDS)}] ğŸ” {category}: {keyword}")

            # æ¤œç´¢
            notes = search_notes(keyword)
            if not notes:
                print(f"  â†’ è¨˜äº‹ãªã—")
                continue

            print(f"  â†’ {len(notes)}ä»¶ç™ºè¦‹")

            for note in notes:
                try:
                    user = note.get("user", {})
                    urlname = user.get("urlname", "")

                    if not urlname or urlname in collected_users:
                        continue

                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—
                    user_info = get_user_info(urlname)
                    if not user_info:
                        continue

                    follower_count = user_info.get("followerCount", 0)

                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if follower_count < CONFIG["min_followers"]:
                        continue
                    if follower_count > CONFIG["max_followers"]:
                        continue

                    collected_users.add(urlname)

                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜äº‹ã‚’åé›†
                    user_notes = get_user_notes(urlname)
                    articles_saved = 0

                    for article in user_notes[:CONFIG["articles_per_user"]]:
                        like_count = article.get("likeCount", 0)

                        if like_count < CONFIG["min_likes_per_article"]:
                            continue

                        power_score = calculate_power_score(like_count, follower_count)

                        if power_score < CONFIG["power_score_threshold"]:
                            continue

                        # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                        article_data = NoteArticle(
                            id=str(article.get("id", "")),
                            title=article.get("name", ""),
                            user_id=str(user.get("id", "")),
                            user_name=user.get("nickname", ""),
                            user_urlname=urlname,
                            like_count=like_count,
                            follower_count=follower_count,
                            power_score=power_score,
                            category=category,
                            keyword=keyword,
                            body_preview=article.get("body", "")[:200],
                            published_at=article.get("publishAt", ""),
                            url=f"https://note.com/{urlname}/n/{article.get('key', '')}",
                        )

                        # ä¿å­˜
                        f.write(json.dumps(asdict(article_data), ensure_ascii=False) + "\n")
                        articles_saved += 1
                        total_articles += 1

                    if articles_saved > 0:
                        print(f"  âœ… @{urlname}: {articles_saved}è¨˜äº‹ (F:{follower_count})")

                    time.sleep(CONFIG["request_delay"])

                except Exception as e:
                    print(f"  âŒ Error: {e}")
                    continue

            # é€²æ—ä¿å­˜
            with open(USERS_FILE, "w", encoding="utf-8") as uf:
                json.dump(list(collected_users), uf, ensure_ascii=False)

    print("\n" + "="*60)
    print("âœ… åé›†å®Œäº†ï¼")
    print(f"ğŸ“Š ç·è¨˜äº‹æ•°: {total_articles}")
    print(f"ğŸ“Š ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(collected_users)}")
    print(f"ğŸ“ ä¿å­˜å…ˆ: {RAW_DATA_FILE}")
    print("="*60)


if __name__ == "__main__":
    collect_data()
